

# Jobs and Scheduling

This document briefly describes how Flink schedules jobs and how it represents and tracks job status on the JobManager.

## Scheduling

Execution resources in Flink are defined through _Task Slots_. Each TaskManager will have one or more task slots, each of which can run one pipeline of parallel tasks. A pipeline consists of multiple successive tasks, such as the _n-th_ parallel instance of a MapFunction together with the _n-th_ parallel instance of a ReduceFunction. Note that Flink often executes successive tasks concurrently: For Streaming programs, that happens in any case, but also for batch programs, it happens frequently.

The figure below illustrates that. Consider a program with a data source, a _MapFunction_, and a _ReduceFunction_. The source and MapFunction are executed with a parallelism of 4, while the ReduceFunction is executed with a parallelism of 3\. A pipeline consists of the sequence Source - Map - Reduce. On a cluster with 2 TaskManagers with 3 slots each, the program will be executed as described below.

![Assigning Pipelines of Tasks to Slots](img/slots.svg)

Internally, Flink defines through [SlotSharingGroup](https://github.com/apache/flink/blob/master//flink-runtime/src/main/java/org/apache/flink/runtime/jobmanager/scheduler/SlotSharingGroup.java) and [CoLocationGroup](https://github.com/apache/flink/blob/master//flink-runtime/src/main/java/org/apache/flink/runtime/jobmanager/scheduler/CoLocationGroup.java) which tasks may share a slot (permissive), respectively which tasks must be strictly placed into the same slot.

## JobManager Data Structures

During job execution, the JobManager keeps track of distributed tasks, decides when to schedule the next task (or set of tasks), and reacts to finished tasks or execution failures.

The JobManager receives the [JobGraph](https://github.com/apache/flink/blob/master//flink-runtime/src/main/java/org/apache/flink/runtime/jobgraph/), which is a representation of the data flow consisting of operators ([JobVertex](https://github.com/apache/flink/blob/master//flink-runtime/src/main/java/org/apache/flink/runtime/jobgraph/JobVertex.java)) and intermediate results ([IntermediateDataSet](https://github.com/apache/flink/blob/master//flink-runtime/src/main/java/org/apache/flink/runtime/jobgraph/IntermediateDataSet.java)). Each operator has properties, like the parallelism and the code that it executes. In addition, the JobGraph has a set of attached libraries, that are necessary to execute the code of the operators.

The JobManager transforms the JobGraph into an [ExecutionGraph](https://github.com/apache/flink/blob/master//flink-runtime/src/main/java/org/apache/flink/runtime/executiongraph/). The ExecutionGraph is a parallel version of the JobGraph: For each JobVertex, it contains an [ExecutionVertex](https://github.com/apache/flink/blob/master//flink-runtime/src/main/java/org/apache/flink/runtime/executiongraph/ExecutionVertex.java) per parallel subtask. An operator with a parallelism of 100 will have one JobVertex and 100 ExecutionVertices. The ExecutionVertex tracks the state of execution of a particular subtask. All ExecutionVertices from one JobVertex are held in an [ExecutionJobVertex](https://github.com/apache/flink/blob/master//flink-runtime/src/main/java/org/apache/flink/runtime/executiongraph/ExecutionJobVertex.java), which tracks the status of the operator as a whole. Besides the vertices, the ExecutionGraph also contains the [IntermediateResult](https://github.com/apache/flink/blob/master//flink-runtime/src/main/java/org/apache/flink/runtime/executiongraph/IntermediateResult.java) and the [IntermediateResultPartition](https://github.com/apache/flink/blob/master//flink-runtime/src/main/java/org/apache/flink/runtime/executiongraph/IntermediateResultPartition.java). The former tracks the state of the _IntermediateDataSet_, the latter the state of each of its partitions.

![JobGraph and ExecutionGraph](img/job_and_execution_graph.svg)

Each ExecutionGraph has a job status associated with it. This job status indicates the current state of the job execution.

A Flink job is first in the _created_ state, then switches to _running_ and upon completion of all work it switches to _finished_. In case of failures, a job switches first to _failing_ where it cancels all running tasks. If all job vertices have reached a final state and the job is not restartable, then the job transitions to _failed_. If the job can be restarted, then it will enter the _restarting_ state. Once the job has been completely restarted, it will reach the _created_ state.

In case that the user cancels the job, it will go into the _cancelling_ state. This also entails the cancellation of all currently running tasks. Once all running tasks have reached a final state, the job transitions to the state _cancelled_.

Unlike the states _finished_, _canceled_ and _failed_ which denote a globally terminal state and, thus, trigger the clean up of the job, the _suspended_ state is only locally terminal. Locally terminal means that the execution of the job has been terminated on the respective JobManager but another JobManager of the Flink cluster can retrieve the job from the persistent HA store and restart it. Consequently, a job which reaches the _suspended_ state wonâ€™t be completely cleaned up.

![States and Transitions of Flink job](img/job_status.svg)

During the execution of the ExecutionGraph, each parallel task goes through multiple stages, from _created_ to _finished_ or _failed_. The diagram below illustrates the states and possible transitions between them. A task may be executed multiple times (for example in the course of failure recovery). For that reason, the execution of an ExecutionVertex is tracked in an [Execution](https://github.com/apache/flink/blob/master//flink-runtime/src/main/java/org/apache/flink/runtime/executiongraph/Execution.java). Each ExecutionVertex has a current Execution, and prior Executions.

![States and Transitions of Task Executions](img/state_machine.svg)