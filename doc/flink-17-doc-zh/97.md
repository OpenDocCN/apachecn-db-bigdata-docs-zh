 $$ \newcommand{\R}{\mathbb{R}} \newcommand{\E}{\mathbb{E}} \newcommand{\x}{\mathbf{x}} \newcommand{\y}{\mathbf{y}} \newcommand{\wv}{\mathbf{w}} \newcommand{\av}{\mathbf{\alpha}} \newcommand{\bv}{\mathbf{b}} \newcommand{\N}{\mathbb{N}} \newcommand{\id}{\mathbf{I}} \newcommand{\ind}{\mathbf{1}} \newcommand{\0}{\mathbf{0}} \newcommand{\unit}{\mathbf{e}} \newcommand{\one}{\mathbf{1}} \newcommand{\zero}{\mathbf{0}} \newcommand\rfrac[2]{^{#1}\!/_{#2}} \newcommand{\norm}[1]{\left\lVert#1\right\rVert} $$

# 多元线性回归

## 描述

多元线性回归试图找到一个最适合所提供的输入数据的线性函数。给定一组值为$(\mathbf{x}, y)$的输入数据，多元线性回归找到一个向量$\mathbf{w}$，使残差平方和最小化:

用矩阵表示法表示，得到如下公式:

该问题有一个封闭形式的解:

但是如果输入数据集太大，则无法对整个数据集进行完整的解析，可以使用随机梯度下降(SGD)来近似解决。SGD首先计算输入数据集的一个随机子集的梯度。给定点$\mathbf{x}_i$的梯度由:

梯度是平均和缩放。缩放由$\gamma = \frac{s}{\sqrt{j}}$定义，其中$s$是初始步长，$j$是当前迭代号。得到的梯度从当前权向量中减去，得到下一个迭代的新权向量:

多元线性回归算法要么计算固定次数的SGD迭代，要么根据动态收敛准则终止。收敛准则是残差平方和的相对变化量:

## 操作

'MultipleLinearRegression'是一个预测因子。因此，它支持“拟合”和“预测”操作。


### 拟合

MultipleLinearRegression在一组'LabeledVector'集合中训练:

*   `fit: DataSet[LabeledVector] =&gt; Unit`

### 预测

多重线性回归对“向量”的所有子类型预测相应的回归值:

*   `predict[T &lt;: Vector]: DataSet[T] =&gt; DataSet[(T, Double)]`

## 参数

多元线性回归的实现可以通过以下参数进行控制:

| 参数 | 描述 |
| --- | --- |
| **Iterations** | 迭代的最大值. (默认值: **10**) |
| **Stepsize** | 梯度下降法的初始步长。该值控制梯度下降方法在梯度的相反方向移动的距离。调优这个参数对于使其稳定并获得更好的性能可能是至关重要的。 (默认值: **0.1**) |
| **ConvergenceThreshold** | 残差平方和的相对变化阈值，直到迭代停止。 (默认值: **None**) |
| **LearningRateMethod** | 学习速率法用于计算每次迭代的有效学习速率。参见所支持的列表 [learning rate methods](optimization.html). (Default value: **LearningRateMethod.Default**) |

## 例子



```
// Create multiple linear regression learner val mlr = MultipleLinearRegression()
.setIterations(10)
.setStepsize(0.5)
.setConvergenceThreshold(0.001)

// Obtain training and testing data set val trainingDS: DataSet[LabeledVector] = ...
val testingDS: DataSet[Vector] = ...

// Fit the linear model to the provided data mlr.fit(trainingDS)

// Calculate the predictions for the test data val predictions = mlr.predict(testingDS)
```



