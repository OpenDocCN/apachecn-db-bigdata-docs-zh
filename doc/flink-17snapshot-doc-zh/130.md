

# 从Source建立Flink

> 译者：[flink.sojb.cn](https://flink.sojb.cn/)


本页面介绍了如何从源代码构建Flink 1.7-SNAPSHOT。

## 建立Flink

为了构建Flink，您需要源代码。无论是[下载一个释放源](http://flink.apache.org/downloads.html)或[克隆的Git仓库](https://github.com/apache/flink)。

此外，您还需要**Maven 3**和**JDK**（Java Development Kit）。Flink **至少**Required**Java 8**才能构建。

_注意：Maven 3.3.x可以构建Flink，但不会正确地遮蔽某些依赖项。Maven 3.2.5正确创建了库。要构建单元测试，请使用Java 8u51或更高版本来防止使用PowerMock运行程序的单元测试失败。_

要从git克隆，请输入：



```
git clone https://github.com/apache/flink
```



构建Flink的最简单方法是运行：



```
mvn clean install -DskipTests
```



这指示[Maven](http://maven.apache.org)（`mvn`）首先删除所有现有的构建（`clean`），然后创建一个新的Flink二进制文件（`install`）。

要加快构建速度，您可以跳过测试，QA插件和JavaDocs：



```
mvn clean install -DskipTests -Dfast
```



默认构建为Hadoop 2添加了特定于Flink的JAR，以允许将Flink与HDFS和YARN一起使用。

## 依赖着色

Flink[遮挡掉](https://maven.apache.org/plugins/maven-shade-plugin/)一些使用的库中，以避免与使用不同版本的这些库的用户程序版本冲突。阴影库包括_Google Guava_，_Asm_，_Apache Curator_，_Apache HTTP Components_，_Netty_等。

最近在Maven中更改了依赖关系着色机制，并要求用户根据Maven版本略微区别地构建Flink：

**Maven 3.0.x，3.1.x和3.2.x** 只需调用`mvn clean install -DskipTests`Flink代码库的根目录即可。

**Maven 3.3.x** 构建必须分两步完成：首先在基本目录中，然后在分发项目中：



```
mvn clean install -DskipTests
cd flink-dist
mvn clean install
```



_注意：_要检查您的Maven版本，请运行`mvn --version`。

## Hadoop版本

信息大多数用户不需要手动执行此 算子操作。该[下载页面](http://flink.apache.org/downloads.html)包含了常见的Hadoop版本的二进制软件包。

Flink依赖于HDFS和YARN，它们都是来自[Apache Hadoop的](http://hadoop.apache.org)依赖项。存在许多不同版本的Hadoop（来自上游项目和不同的Hadoop发行版）。如果使用错误的版本组合，则可能发生异常。

Hadoop仅从2.4.0版本开始支持。您还可以指定要构建的特定Hadoop版本：



```
mvn clean install -DskipTests -Dhadoop.version=2.6.1
```



### 供应商特定版本

要针对特定​​于供应商的Hadoop版本构建Flink，请发出以下命令：



```
mvn clean install -DskipTests -Pvendor-repos -Dhadoop.version=2.6.1-cdh5.0.0
```



在`-Pvendor-repos`激活一个Maven [建立简档](http://maven.apache.org/guides/introduction/introduction-to-profiles.html)，其包括流行的Hadoop厂商如Cloudera的，Hortonworks，或MAPR的存储库。

## Scala版本

信息纯粹使用Java API和库的用户可以_忽略_此部分。

Flink具有用[Scala](http://scala-lang.org)编写的API，库和运行时模块。Scala API和库的用户可能必须将Scala版本的Flink与其项目的Scala版本相匹配（因为Scala不是严格向后兼容的）。

Flink 1.4目前仅使用Scala版本2.11构建。

我们正在努力支持Scala 2.12，但Scala 2.12中的某些重大更改使这更加复杂。请查看[此JIRA问题](https://issues.apache.org/jira/browse/FLINK-7811)以获取更新。

## 加密文件系统

如果您的主目录已加密，则可能会遇到`java.io.IOException: File name too long`异常。某些加密文件系统（如Ubuntu使用的encfs）不允许长文件名，这是导致此错误的原因。

解决方法是添加：



```
<args>
    <arg>-Xmax-classfile-name</arg>
    <arg>128</arg>
</args>
```



在`pom.xml`导致错误的模块文件的编译器配置中。例如，如果`flink-yarn`模块中出现错误，则应在`&lt;configuration&gt;`标记下添加上述代码`scala-maven-plugin`。有关更多信息，请参阅[此问题](https://issues.apache.org/jira/browse/FLINK-2003)。

