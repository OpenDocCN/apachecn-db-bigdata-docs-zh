# Path Hierarchy Tokenizer（路径层次分词器）

**path_hierarchy tokenizer** 把分层的值看成是文件路径，用路径分隔符分割文本，输出树上的各个节点。

原文链接 : [https://www.elastic.co/guide/en/elasticsearch/reference/5.3/analysis-pathhierarchy-tokenizer.html](https://www.elastic.co/guide/en/elasticsearch/reference/5.3/analysis-pathhierarchy-tokenizer.html)

译文链接 : [http://www.apache.wiki/pages/viewpage.action?pageId=10028999](http://www.apache.wiki/pages/viewpage.action?pageId=10028999)

贡献者 : [陈益雷](/display/~chenyilei)，[ApacheCN](/display/~apachecn)，[Apache中文网](/display/~apachechina)

## **输出示例**

```
POST _analyze
{
  "tokenizer": "path_hierarchy",
  "text": "/one/two/three"
}
```

输出为：

```
[ /one, /one/two, /one/two/three ]
```

## **配置**

**path_hierarchy tokenizer **有以下参数：

| `delimiter` | 路径分隔符。默认是 / 。 |
| `replacement` | 路径分隔符的替换字符。默认是 `delimiter`. |
| `buffer_size` | 一次读到词元缓冲区的字符数。默认是 1024 。 词元缓冲区以此大小增长，只到读完所有的文本。建议不要更改这项配置。 |
| `reverse` | 若为 true ，以相反的顺序发射词元。默认是 false 。 |
| `skip` | 忽视的原始词元的数量。默认是0。 |

## **配置示例**

下面的例子中，我们配置 遇到 - 时分割 并替换为 /  ，忽视前2个词元：

```
PUT my_index
{
  "settings": {
    "analysis": {
      "analyzer": {
        "my_analyzer": {
          "tokenizer": "my_tokenizer"
        }
      },
      "tokenizer": {
        "my_tokenizer": {
          "type": "path_hierarchy",
          "delimiter": "-",
          "replacement": "/",
          "skip": 2
        }
      }
    }
  }
}

POST my_index/_analyze
{
  "analyzer": "my_analyzer",
  "text": "one-two-three-four-five"
}
```

输出为：

```
[ /three, /three/four, /three/four/five ]
```

若配置 **reverse** 为 true ，输出为：

```
[ one/two/three/, two/three/, three/ ]
```