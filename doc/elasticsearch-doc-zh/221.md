# cat shards

原文链接 : [https://www.elastic.co/guide/en/elasticsearch/reference/5.0/cat-shards.html](https://www.elastic.co/guide/en/elasticsearch/reference/5.0/cat-shards.html)

译文链接 : [http://www.apache.wiki/display/Elasticsearch/cat+shards](http://www.apache.wiki/display/Elasticsearch/cat+shards)

贡献者 : [那伊抹微笑](/display/~wangyangting)

**shards** 命令详细的描述了节点包含的分片信息。它将告诉您它是一个主分片还是一个副本，和文档的数量，硬盘上占用的字节数，以及节点所在的位置。下面我将看一个单独的索引，它有 **3** 个主分片和 **0** 个副本。

```
% curl 192.168.56.20:9200/_cat/shards
wiki1 0 p STARTED 3014 31.1mb 192.168.56.10 H5dfFeA
wiki1 1 p STARTED 3013 29.6mb 192.168.56.30 bGG90GE
wiki1 2 p STARTED 3973 38.1mb 192.168.56.20 I8hydUG
```

## Index pattern（索引模式）

如果有许多分片，您也许想要限制在输出中显示的索引。您可以一直使用 **grep**，但是您可以通过提供一个 **index** **pattern**（索引模式）到尾部以节省带宽。

```
% curl 192.168.56.20:9200/_cat/shards/wiki*
wiki2 0 p STARTED 197 3.2mb 192.168.56.10 H5dfFeA
wiki2 1 p STARTED 205 5.9mb 192.168.56.30 bGG90GE
wiki2 2 p STARTED 275 7.8mb 192.168.56.20 I8hydUG
```

## Relocation（迁移）

假设您在检测集群健康时发现迁移的分片。它们原来在哪里，并且迁移到哪呢？

```
% curl 192.168.56.10:9200/_cat/health
1384315316 20:01:56 foo green 3 3 12 6 2 0 0
% curl 192.168.56.10:9200/_cat/shards | fgrep RELO
wiki1 0 r RELOCATING 3014 31.1mb 192.168.56.20 I8hydUG -> 192.168.56.30 bGG90GE
wiki1 1 r RELOCATING 3013 29.6mb 192.168.56.10 H5dfFeA -> 192.168.56.30 bGG90GE
```

## Shard states（分片状态）

在一个分配能使用之前，它会经过一个 ``**INITIALIZING**（初始化）状态，**shards** 可以告诉您更详细的信息。``

```
% curl -XPUT 192.168.56.20:9200/_settings -d'{"number_of_replicas":1}'
{"acknowledged":true}
% curl 192.168.56.20:9200/_cat/shards
wiki1 0 p STARTED      3014 31.1mb 192.168.56.10 H5dfFeA
wiki1 0 r INITIALIZING    0 14.3mb 192.168.56.30 bGG90GE
wiki1 1 p STARTED      3013 29.6mb 192.168.56.30 bGG90GE
wiki1 1 r INITIALIZING    0 13.1mb 192.168.56.20 I8hydUG
wiki1 2 r INITIALIZING    0   14mb 192.168.56.10 H5dfFeA
wiki1 2 p STARTED      3973 38.1mb 192.168.56.20 I8hydUG
```

如果一个分片不能够被分配，例如，你分配的分片数量超过了集群中节点的数量，分片将保持 `**UNASSIGNED**（未分配的）状态与 [reason code](https://www.elastic.co/guide/en/elasticsearch/reference/5.0/cat-shards.html#reason-unassigned "Reasons for unassigned shardedit")（异常代码）`**ALLOCATION_FAILED**（分配失败）。``

```
% curl -XPUT 192.168.56.20:9200/_settings -d'{"number_of_replicas":3}'
% curl 192.168.56.20:9200/_cat/health
1384316325 20:18:45 foo yellow 3 3 9 3 0 0 3
% curl 192.168.56.20:9200/_cat/shards
wiki1 0 p STARTED    3014 31.1mb 192.168.56.10 H5dfFeA
wiki1 0 r STARTED    3014 31.1mb 192.168.56.30 bGG90GE
wiki1 0 r STARTED    3014 31.1mb 192.168.56.20 I8hydUG
wiki1 0 r UNASSIGNED ALLOCATION_FAILED
wiki1 1 r STARTED    3013 29.6mb 192.168.56.10 H5dfFeA
wiki1 1 p STARTED    3013 29.6mb 192.168.56.30 bGG90GE
wiki1 1 r STARTED    3013 29.6mb 192.168.56.20 I8hydUG
wiki1 1 r UNASSIGNED ALLOCATION_FAILED
wiki1 2 r STARTED    3973 38.1mb 192.168.56.10 H5dfFeA
wiki1 2 r STARTED    3973 38.1mb 192.168.56.30 bGG90GE
wiki1 2 p STARTED    3973 38.1mb 192.168.56.20 I8hydUG
wiki1 2 r UNASSIGNED ALLOCATION_FAILED
```

## Reasons for unassigned shard

对于在 **unassigned state**（未分配状态）中的分片，这里有一些可能的原因 : 

| Reason Code（异常代码） | Description（描述） |
| `INDEX_CREATED` | Unassigned as a result of an API creation of an index. |
| `CLUSTER_RECOVERED` | Unassigned as a result of a full cluster recovery. |
| `INDEX_REOPENED` | Unassigned as a result of opening a closed index. |
| `DANGLING_INDEX_IMPORTED` | Unassigned as a result of importing a dangling index. |
| `NEW_INDEX_RESTORED` | Unassigned as a result of restoring into a new index. |
| `EXISTING_INDEX_RESTORED` | Unassigned as a result of restoring into a closed index. |
| `REPLICA_ADDED` | Unassigned as a result of explicit addition of a replica. |
| `ALLOCATION_FAILED` | Unassigned as a result of a failed allocation of the shard. |
| `NODE_LEFT` | Unassigned as a result of the node hosting it leaving the cluster. |
| `REROUTE_CANCELLED` | Unassigned as a result of explicit cancel reroute command. |
| `REINITIALIZED` | When a shard moves from started back to initializing, for example, with shadow replicas. |
| `REALLOCATED_REPLICA` | A better replica location is identified and causes the existing replica allocation to be cancelled. |