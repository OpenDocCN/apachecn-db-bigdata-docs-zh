# Translog（事务日志）

原文链接 : [https://www.elastic.co/guide/en/elasticsearch/reference/5.3/index-modules-translog.html](https://www.elastic.co/guide/en/elasticsearch/reference/5.3/index-modules-translog.html)

译文链接 : [Translog（事务日志）](/pages/viewpage.action?pageId=10028549)

贡献者 : @苏涛，[ApacheCN](/display/~apachecn)，[Apache中文网](/display/~apachechina)

### 事务日志

Lucene的修改只有在提交的时候保存在磁盘上，这是个相对沉重的操作，因此不能在每次索引或删除操作之后执行。一次提交之后另一次提交之前如果发生了进程退出或硬件故障的事件，这之间的修改会丢失。

为了防止数据丢失，每个分片都有**_transaction log_** （事务日志）或与之相关的日志。任何索引或删除操作在Lucene索引内部执行之后会被写入事务日志。

如果发生了崩溃事件，当分片恢复的时候，最近的事务可以根据事务日志进行恢复。

Elasticsearch flush（刷新）操作是执行Lucene提交并开始新的事务日志的过程。会自动进行后台执行来确保事务日志不会变得太大，这会使重做操作在恢复时花费大量的时间。可以通过接口调用，虽然很少需要手动执行。

### 刷新设置

以下[动态可更新设置](https://www.elastic.co/guide/en/elasticsearch/reference/5.3/indices-update-settings.html)可控制内存缓冲区刷新到磁盘的频率：

_**`index.translog.flush_threshold_size`**_

    一旦事务日志达到了这个大小，刷新操作就会执行。默认值为_**512mb**_

### 事务日志设置

事务日志的数据仅在事务同步和提交之后保存在磁盘上。如果发生了硬件错误，前一次事务日志提交之后的任何数据写入都会丢失。

默认情况下，如果_**index.translog.durability**_设置为异步，或者在每个[索引](https://www.elastic.co/guide/en/elasticsearch/reference/5.3/docs-index_.html)，[删除](https://www.elastic.co/guide/en/elasticsearch/reference/5.3/docs-delete.html)，[更新](https://www.elastic.co/guide/en/elasticsearch/reference/5.3/docs-update.html)或[批量请求](https://www.elastic.co/guide/en/elasticsearch/reference/5.3/docs-bulk.html)的末尾设置为`request` （默认），则Elasticsearch每5秒提交一次translog。事实上，Elasticsearch只会在事务日志被成功地同步和提交给主分片和任何分配的副本分片之后，才能向客户端报告成功执行索引，删除，更新或批量请求。

每个索引可使用下面[动态更新的设置](https://www.elastic.co/guide/en/elasticsearch/reference/5.3/indices-update-settings.html)控制事务日志的行为：

_**index.translog.sync_interval**_

    无论写入操作如何，translog都被同步到磁盘和提交的频率。默认为**5秒**。不允许小于**100ms**的值。

_**index.translog.durability**_

    在每次索引，删除，更新或批量请求之后是否同步并提交translog。此设置接受以下参数：

    **request**

        （默认）每次请求之后执行同步和提交。在硬件故障的情况下，所有收到的写入会事先提交到磁盘上。

    **async**

        每经过一个同步间隔，都会在后台执行同步和提交。在硬件故障的情况下，自从最后一次自动提交之后收到的写入都会被丢弃

### 事务日志损坏该如何处理

在某些情况下（错误的驱动器，用户错误），translog可能会损坏。当由于不匹配的校验而检测到这种损坏，Elasticsearch将该分片标记为失败，并拒绝将该数据副本分配给该节点，如果可用，则从副本中恢复。

如果没有Elasticsearch可以成功恢复的数据副本，用户可能希望以丢失当前包含在translog中的数据为代价来恢复作为分片一部分的数据。我们为此提供了一个命令行工具，**elasticsearch-translog**。

警告

**elasticsearch-translog**工具不应该在Elasticsearch运行时运行，并且您将永久丢失仅在translog中包含的文档！

为了运行**elasticsearch-translog**工具，使用-d选项指定truncate子命令以及损坏的translog的目录：

```
$ bin/elasticsearch-translog truncate -d /var/lib/elasticsearchdata/nodes/0/indices/P45vf_YQRhqjfwLMUvSqDw/0/translog/
Checking existing translog files
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
!   WARNING: Elasticsearch MUST be stopped before running this tool   !
!                                                                     !
!   WARNING:    Documents inside of translog files will be lost       !
!                                                                     !
!   WARNING:          The following files will be DELETED!            !
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
--> data/nodes/0/indices/P45vf_YQRhqjfwLMUvSqDw/0/translog/translog-41.ckp
--> data/nodes/0/indices/P45vf_YQRhqjfwLMUvSqDw/0/translog/translog-6.ckp
--> data/nodes/0/indices/P45vf_YQRhqjfwLMUvSqDw/0/translog/translog-37.ckp
--> data/nodes/0/indices/P45vf_YQRhqjfwLMUvSqDw/0/translog/translog-24.ckp
--> data/nodes/0/indices/P45vf_YQRhqjfwLMUvSqDw/0/translog/translog-11.ckp

Continue and DELETE files? [y/N] y
Reading translog UUID information from Lucene commit from shard at [data/nodes/0/indices/P45vf_YQRhqjfwLMUvSqDw/0/index]
Translog Generation: 3
Translog UUID      : AxqC4rocTC6e0fwsljAh-Q
Removing existing translog files
Creating new empty checkpoint at [data/nodes/0/indices/P45vf_YQRhqjfwLMUvSqDw/0/translog/translog.ckp]
Creating new empty translog at [data/nodes/0/indices/P45vf_YQRhqjfwLMUvSqDw/0/translog/translog-3.tlog]
Done.
```

您还可以使用-h选项来获取**elasticsearch-translog**工具支持的所有选项和参数的列表。